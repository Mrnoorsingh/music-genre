{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os,random\n",
    "import numpy as np\n",
    "import augmentation\n",
    "import collections\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path(\"genres\")\n",
    "genre_class=[]\n",
    "audio_data=[]\n",
    "cat_2_num={}\n",
    "numeric_category=-1\n",
    "\n",
    "for folder in path.glob(\"*\"):\n",
    "    numeric_category+=1\n",
    "    category=str(folder).split(\"/\")[-1]\n",
    "    cat_2_num[category]=numeric_category\n",
    "\n",
    "    for file in folder.glob(\"*.au\"):\n",
    "        data=str(file).split(\"/\")[-1]\n",
    "        audio_data.append(data)\n",
    "        genre_class.append(cat_2_num[category])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split datset\n",
    "zip_list=list(zip(audio_data,genre_class))\n",
    "random.seed(8)\n",
    "random.shuffle(zip_list)\n",
    "\n",
    "train_set=zip_list[:int(0.8*(len(zip_list)))]\n",
    "test_set=zip_list[int(0.8*(len(zip_list))):int(0.9*(len(zip_list)))]\n",
    "val_set=zip_list[int(0.9*(len(zip_list))):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define clip path and load \n",
    "def audio_clip(clip):\n",
    "    folder_name=clip[0].split(\".\")[0]\n",
    "    file_path=path/folder_name/clip[0]\n",
    "    audio_file,sr=librosa.load(file_path)#load file as time series in numpy array.sampling rate=22050\n",
    "    return audio_file,folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images(data,target_folder):\n",
    "    #save training set images into the target directory\n",
    "    for clip in train_set:\n",
    "        audio_file=audio_clip(clip)\n",
    "        if target_folder==\"train set\":\n",
    "            audio_file=augmentation.augmentation(audio_file)\n",
    "            mel=list(map(librosa.feature.melspectrogram,audio_file))#compute melspectrogram\n",
    "            for i in range(len(mel)):\n",
    "                librosa.display.specshow(librosa.power_to_db(mel[i],ref=np.max),y_axis=\"off\",x_axis=\"off\")#plot melspectrogram\n",
    "        else:\n",
    "            mel=librosa.feature.melspectrogram(audio_file)\n",
    "        \n",
    "        #save melspectrograms in target folders\n",
    "        image_name=os.path.splitext(clip[0])[0]\n",
    "        dir_path=Path(target_folder)/folder_name\n",
    "        dir_path.mkdir(parents=True,exist_ok=True)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(dir_path/(image_name+str(i)+\".jpg\"),bbox_inches='tight',pad_inches = 0)\n",
    "        plt.close()\n",
    "\n",
    "create_images(train_set,\"train set\")\n",
    "create_images(val_set,\"val set\")\n",
    "create_images(test_set,\"test set\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import zero_crossing_rate,rmse,mfcc,chroma_stft,spectral_centroid,spectral_bandwidth,spectral_rolloff,spectral_contrast\n",
    "from librosa.beat import tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features for machine learning models\n",
    "def create_features(audio):\n",
    "    #time domain features\n",
    "    zcr=zero_crossing_rate(audio)#array of fractions of zero crossing of each frame\n",
    "    rms=rmse(audio)#array of rmse of each frame\n",
    "    tempo_=tempo(audio)#beats per minute (scaler value)\n",
    "    \n",
    "    #frequency domain features\n",
    "    mfcc_=mfcc(audio,n_mfcc=20)#computes mel-freq cepstral coefficients\n",
    "    chroma=chroma_stft(audio)#computes chroma bins(12) for each frame\n",
    "    spec_cent=spectral_centroid(audio)#centroid frequencies\n",
    "    spec_band=spectral_bandwidth(audio,p=2)#pth order moment about spectral centroid\n",
    "    spec_cont=spectral_contrast(audio)#min. max. difference between frequency bands\n",
    "    spec_rolloff=spectral_rolloff(audio)#roll off frequency\n",
    "    \n",
    "    #take mean of each feature across all frames\n",
    "    features=[zcr,rms,spec_cent,spec_band,spec_rolloff,spec_cont,mfcc_,chroma]\n",
    "    features=list(map(lambda x : np.mean(x,axis=1),features))\n",
    "    features=[tempo_]+features\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataset):\n",
    "    temp=[]\n",
    "    count=0\n",
    "    for clip in dataset:\n",
    "        \n",
    "        audio,label=audio_clip(clip)\n",
    "        audio_clips=augmentation.augmentation(audio)\n",
    "        for audio in audio_clips:\n",
    "            feature=create_features(audio)\n",
    "            flat_list=[value for sublist in feature for value in sublist]#flatten the extracted list    \n",
    "            temp.append([label]+flat_list)\n",
    "    \n",
    "    return temp   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features of all examples\n",
    "features=extract_features(zip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column list for dataframe\n",
    "column=[\"label\",\"tempo_\",\"zcr\",\"rms\",\"spec_cent\",\"spec_band\",\"spec_rolloff\"]\n",
    "mfcc_col=[\"mfcc\"+str(i) for i in range(20)]\n",
    "chroma_col=[\"chroma\"+str(i) for i in range(12)]\n",
    "contrast=[\"spec_cont\"+str(i) for i in range(7)]\n",
    "column.extend(contrast+mfcc_col+chroma_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe\n",
    "df1=pd.DataFrame(features,columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
