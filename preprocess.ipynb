{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os,random\n",
    "import numpy as np\n",
    "import augmentation\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path(\"genres\")\n",
    "genre_class=[]\n",
    "audio_data=[]\n",
    "cat_2_num={}\n",
    "numeric_category=-1\n",
    "\n",
    "for folder in path.glob(\"*\"):\n",
    "    numeric_category+=1\n",
    "    category=str(folder).split(\"/\")[-1]\n",
    "    cat_2_num[category]=numeric_category\n",
    "\n",
    "    for file in folder.glob(\"*.au\"):\n",
    "        data=str(file).split(\"/\")[-1]\n",
    "        audio_data.append(data)\n",
    "        genre_class.append(cat_2_num[category])\n",
    "\n",
    "#num_2_cat={value:key for key,value in cat_2_num.items()}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split datset\n",
    "zip_list=list(zip(audio_data,genre_class))\n",
    "random.seed(8)\n",
    "random.shuffle(zip_list)\n",
    "\n",
    "train_set=zip_list[:int(0.8*(len(zip_list)))]\n",
    "test_set=zip_list[int(0.8*(len(zip_list))):int(0.9*(len(zip_list)))]\n",
    "val_set=zip_list[int(0.9*(len(zip_list))):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_clip(clip):\n",
    "    folder_name=clip[0].split(\".\")[0]\n",
    "    file_path=path/folder_name/clip[0]\n",
    "    audio_file,sr=librosa.load(file_path)#load file as time series in numpy array.sampling rate=22050\n",
    "    return audio_file,folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images(data,target_folder):\n",
    "    #save training set images into the target directory\n",
    "    for clip in train_set:\n",
    "        audio_file=audio_clip(clip)\n",
    "        if target_folder==\"train set\":\n",
    "            audio_file=augmentation.augmentation(audio_file)\n",
    "            mel=list(map(librosa.feature.melspectrogram,audio_file))#compute melspectrogram\n",
    "            for i in range(len(mel)):\n",
    "                librosa.display.specshow(librosa.power_to_db(mel[i],ref=np.max),y_axis=\"off\",x_axis=\"off\")#plot melspectrogram\n",
    "        else:\n",
    "            mel=librosa.feature.melspectrogram(audio_file)\n",
    "        \n",
    "        #save melspectrograms in target folders\n",
    "        image_name=os.path.splitext(clip[0])[0]\n",
    "        dir_path=Path(target_folder)/folder_name\n",
    "        dir_path.mkdir(parents=True,exist_ok=True)\n",
    "        plt.axis(\"off\")\n",
    "        #plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "        #plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "        plt.savefig(dir_path/(image_name+str(i)+\".jpg\"),bbox_inches='tight',pad_inches = 0)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_images(train_set,\"train set\")\n",
    "create_images(val_set,\"val set\")\n",
    "create_images(test_set,\"test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import zero_crossing_rate,rmse,mfcc,chroma_stft,spectral_centroid,spectral_bandwidth,spectral_rolloff,spectral_contrast\n",
    "from librosa.beat import tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features for machine learning models\n",
    "def extract_features(audio,label):\n",
    "    #time domain features\n",
    "    zcr=zero_crossing_rate(audio)#array of fractions of zero crossing of each frame\n",
    "    rms=rmse(audio)#array of rmse of each frame\n",
    "    tempo_=tempo(audio)#beats per minute (scaler value)\n",
    "    \n",
    "    #frequency domain features\n",
    "    mfcc_=mfcc(audio,n_mfcc=20)#computes mel-freq cepstral coefficients\n",
    "    chroma=chroma_stft(audio)#computes chroma bins(12) for each frame\n",
    "    spec_cent=spectral_centroid(audio)#centroid frequencies\n",
    "    spec_band=spectral_bandwidth(audio,p=2)#pth order moment about spectral centroid\n",
    "    spec_cont=spectral_contrast(audio)#min. max. difference between frequency bands\n",
    "    spec_rolloff=spectral_rolloff(audio)#roll off frequency\n",
    "    print(mfcc_)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noor/.local/lib/python3.6/site-packages/librosa/beat.py:306: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  hop_length=hop_length))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-185.75844174 -185.08224408 -205.88324486 ... -186.4421659\n",
      "  -186.74646656 -186.11255643]\n",
      " [  81.69084719   80.81920988   78.60971069 ...   77.04790722\n",
      "    77.62412022   73.99956339]\n",
      " [ -26.14461526  -25.88990293  -25.05485059 ...  -13.56072724\n",
      "   -16.26752282  -14.77464918]\n",
      " ...\n",
      " [  14.86819169   10.38473117    3.13663396 ...    9.86211682\n",
      "     6.45083576    0.28265808]\n",
      " [  -8.6967483   -12.21011708  -13.06366112 ...    9.15883259\n",
      "     9.90078226    5.65830886]\n",
      " [  10.44503383    8.63962071    6.01686028 ...    9.00672282\n",
      "     5.23834012    1.70440875]]\n"
     ]
    }
   ],
   "source": [
    "x,y=audio_clip(train_set[0])\n",
    "c=extract_features(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zcr-(1,1293)\n",
    "#rms-(1,1293)\n",
    "#tempo=(1,)\n",
    "#mfcc=(20,1293)\n",
    "#chroma=(12,1293)\n",
    "#cent=(1,1293)\n",
    "#band=(1,1293)\n",
    "#cont(7,1293)\n",
    "#roll(1,1293)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
